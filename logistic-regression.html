<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="9 Logistic Regression | Using Spark in  R  with the sparklyr package" />
<meta property="og:type" content="book" />





<meta name="author" content="Federico Girosi (DHCRC)" />

<meta name="date" content="2020-01-21" />


<meta name="description" content="9 Logistic Regression | Using Spark in  R  with the sparklyr package">

<title>9 Logistic Regression | Using Spark in  R  with the sparklyr package</title>

<link href="libs/tufte-css/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css/envisioned.css" rel="stylesheet" />
<link href="libs/msmb-css/msmb.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);

e.style.display = ((e.style.display!='none') ? 'none' : 'block');

if(f.classList.contains('fa-plus-square')) {
    f.classList.add('fa-minus-square')
    f.classList.remove('fa-plus-square')
} else {
    f.classList.add('fa-plus-square')
    f.classList.remove('fa-minus-square')
}

}
</script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="test.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul class="navbar">
<li class="msmb"><p class="title">Using Spark in <font face="Courier New"> R </font> with the <font face="Courier New">sparklyr</font> package<p><p class="author">Federico Girosi (DHCRC)</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="index.html"><span class="toc-section-number">1</span> Introduction</a>
<a href="setting-up-spark-on-your-laptop.html"><span class="toc-section-number">2</span> Setting up Spark on your laptop</a>
<a href="launching-spark-and-importing-a-csv-file.html"><span class="toc-section-number">3</span> Launching Spark and importing a CSV file</a>
<a href="working-with-data-in-spark.html"><span class="toc-section-number">4</span> Working with data in Spark</a>
<a href="merging-and-subsetting.html"><span class="toc-section-number">5</span> Merging and subsetting</a>
<a href="linear-regression.html"><span class="toc-section-number">6</span> Linear regression</a>
<a href="user-defined-functions.html"><span class="toc-section-number">7</span> User defined functions</a>
<a href="user-defined-functions-and-hive-sql.html"><span class="toc-section-number">8</span> User defined functions and HIVE SQL</a>
<a id="active-page" href="logistic-regression.html"><span class="toc-section-number">9</span> Logistic Regression</a>
<a href="appendix-a-data-description.html">Appendix A: data description</a>
<a href="references.html">References</a>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html><body><div id="logistic-regression" class="section level1" number="9">
<h1 number="9">
<span class="header-section-number">9</span> Logistic Regression</h1>
<p>We proceed in stages. First we use the <font face="Courier New">sparklyr</font> machine learning library to run a logit and to its summary statistics and coefficients in a local table, and then we use a logit to make predictions.</p>
<div id="logit-extracting-the-coefficients" class="section level2" number="9.1">
<h2 number="9.1">
<span class="header-section-number">9.1</span> Logit: extracting the coefficients</h2>
<p>The equivalent of <strong>glm</strong>() in <font face="Courier New">sparklyr</font> is <strong>ml_generalized_linear_regression</strong>(), that has a syntax that is very similar to the one of glm:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="logistic-regression.html#cb49-1"></a>f =<span class="st"> </span>heart <span class="op">~</span><span class="st"> </span>agecat <span class="op">+</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>state <span class="op">+</span><span class="st"> </span>bmi <span class="op">+</span><span class="st"> </span>smoking <span class="op">+</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span>education <span class="op">+</span><span class="st"> </span>marital_status </span>
<span id="cb49-2"><a href="logistic-regression.html#cb49-2"></a>logit  &lt;-<span class="st"> </span><span class="kw">ml_generalized_linear_regression</span>(dat, <span class="dt">formula =</span> f, <span class="dt">family =</span> <span class="st">"binomial"</span>, <span class="dt">link =</span> <span class="st">"logit"</span>)</span>
<span id="cb49-3"><a href="logistic-regression.html#cb49-3"></a>logit <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb49-4"><a href="logistic-regression.html#cb49-4"></a><span class="st">  </span><span class="kw">kable</span>(<span class="dt">digits=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">3</span>),<span class="dt">format.args =</span> <span class="kw">list</span>(<span class="dt">big.mark=</span><span class="st">","</span>),</span>
<span id="cb49-5"><a href="logistic-regression.html#cb49-5"></a>        <span class="dt">caption=</span><span class="st">"**Logit coefficients**. "</span>)</span></code></pre></div>
<p><!--
<caption>--><span class="marginnote shownote"><span id="tab:logit">Table 3: </span><strong>Logit coefficients</strong>.</span><!--</caption>--></p>
<table>
<thead><tr class="header">
<th align="center">term</th>
<th align="right">estimate</th>
<th align="right">std.error</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">(Intercept)</td>
<td align="right">-0.73</td>
<td align="right">0.02</td>
<td align="right">-30.23</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="center">agecat_18.0, 35.0</td>
<td align="right">-5.19</td>
<td align="right">0.02</td>
<td align="right">-334.71</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="center">agecat_35.0, 45.0</td>
<td align="right">-3.46</td>
<td align="right">0.01</td>
<td align="right">-343.03</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="center">agecat_45.0, 55.0</td>
<td align="right">-2.31</td>
<td align="right">0.01</td>
<td align="right">-300.26</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="center">agecat_55.0, 65.0</td>
<td align="right">-1.39</td>
<td align="right">0.01</td>
<td align="right">-208.65</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="center">agecat_65.0, 75.0</td>
<td align="right">-0.71</td>
<td align="right">0.01</td>
<td align="right">-117.69</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="center">agecat_75.0, 85.0</td>
<td align="right">-0.25</td>
<td align="right">0.01</td>
<td align="right">-45.21</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="center">gender_F</td>
<td align="right">-0.66</td>
<td align="right">0.00</td>
<td align="right">-211.33</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="center">state_Aboda</td>
<td align="right">0.01</td>
<td align="right">0.02</td>
<td align="right">0.65</td>
<td align="right">0.514</td>
</tr>
<tr class="even">
<td align="center">state_Sintbu</td>
<td align="right">0.01</td>
<td align="right">0.02</td>
<td align="right">0.79</td>
<td align="right">0.430</td>
</tr>
<tr class="odd">
<td align="center">state_Isnor</td>
<td align="right">0.02</td>
<td align="right">0.02</td>
<td align="right">0.89</td>
<td align="right">0.376</td>
</tr>
<tr class="even">
<td align="center">state_Itsware</td>
<td align="right">0.01</td>
<td align="right">0.02</td>
<td align="right">0.41</td>
<td align="right">0.680</td>
</tr>
<tr class="odd">
<td align="center">state_Haivismal</td>
<td align="right">0.01</td>
<td align="right">0.02</td>
<td align="right">0.36</td>
<td align="right">0.721</td>
</tr>
<tr class="even">
<td align="center">state_Blitzbar</td>
<td align="right">0.00</td>
<td align="right">0.02</td>
<td align="right">-0.06</td>
<td align="right">0.950</td>
</tr>
<tr class="odd">
<td align="center">state_Morgenor</td>
<td align="right">0.01</td>
<td align="right">0.02</td>
<td align="right">0.37</td>
<td align="right">0.714</td>
</tr>
<tr class="even">
<td align="center">bmi_Overweight</td>
<td align="right">-0.01</td>
<td align="right">0.01</td>
<td align="right">-0.66</td>
<td align="right">0.510</td>
</tr>
<tr class="odd">
<td align="center">bmi_Normal</td>
<td align="right">-0.15</td>
<td align="right">0.01</td>
<td align="right">-10.11</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="center">bmi_Obese</td>
<td align="right">0.20</td>
<td align="right">0.01</td>
<td align="right">13.17</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="center">smoking_Never smoked</td>
<td align="right">-0.03</td>
<td align="right">0.00</td>
<td align="right">-6.46</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="center">smoking_Ex-smoker</td>
<td align="right">0.23</td>
<td align="right">0.00</td>
<td align="right">48.13</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="center">income_70K+</td>
<td align="right">-0.21</td>
<td align="right">0.01</td>
<td align="right">-33.62</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="center">income_&lt;20K</td>
<td align="right">0.25</td>
<td align="right">0.01</td>
<td align="right">43.95</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="center">income_50K-70K</td>
<td align="right">-0.13</td>
<td align="right">0.01</td>
<td align="right">-20.44</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="center">income_20K-30K</td>
<td align="right">0.14</td>
<td align="right">0.01</td>
<td align="right">23.46</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="center">income_40K-50K</td>
<td align="right">-0.02</td>
<td align="right">0.01</td>
<td align="right">-3.62</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="center">education_University</td>
<td align="right">0.06</td>
<td align="right">0.01</td>
<td align="right">10.21</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="center">education_Diploma</td>
<td align="right">0.05</td>
<td align="right">0.01</td>
<td align="right">7.31</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="center">education_Certif</td>
<td align="right">0.00</td>
<td align="right">0.01</td>
<td align="right">0.08</td>
<td align="right">0.940</td>
</tr>
<tr class="odd">
<td align="center">education_NoCertif</td>
<td align="right">0.07</td>
<td align="right">0.01</td>
<td align="right">11.65</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="center">marital_status_partnered</td>
<td align="right">-0.07</td>
<td align="right">0.00</td>
<td align="right">-15.38</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="center">marital_status_separated</td>
<td align="right">-0.11</td>
<td align="right">0.01</td>
<td align="right">-16.36</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="center">marital_status_single</td>
<td align="right">-0.18</td>
<td align="right">0.01</td>
<td align="right">-22.24</td>
<td align="right">0.000</td>
</tr>
</tbody>
</table>
<p>There is another command which is specific to logit, <strong>ml_logistic_regression</strong>(), which produces different output. We will use it in the next example.</p>
</div>
<div id="making-predictions-with-logit" class="section level2" number="9.2">
<h2 number="9.2">
<span class="header-section-number">9.2</span> Making predictions with logit</h2>
<p>Here we use the same data as in the previous example to build a simple predictive model and to test its accuracy using cross validation.</p>
<p>It is common to test the accuracy of a model using several cross-validation samples, that we can create with the <font face="Courier New">sparklyr</font> function <strong>sdf_random_split</strong>(), that takes one Spark tables and splits it randomly in chunks of given size. We use it as follows:</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="logistic-regression.html#cb50-1"></a>weights =<span class="st"> </span>purrr<span class="op">::</span><span class="kw">set_names</span>(<span class="kw">rep</span>(<span class="fl">0.1</span>, <span class="dv">10</span>), <span class="kw">paste0</span>(<span class="st">"fold"</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>))</span>
<span id="cb50-2"><a href="logistic-regression.html#cb50-2"></a>weights</span></code></pre></div>
<pre><code>##  fold1  fold2  fold3  fold4  fold5  fold6  fold7  fold8  fold9 fold10 
##    0.1    0.1    0.1    0.1    0.1    0.1    0.1    0.1    0.1    0.1</code></pre>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="logistic-regression.html#cb52-1"></a>vfolds &lt;-<span class="st"> </span><span class="kw">sdf_random_split</span>(dat, <span class="dt">weights =</span> weights, <span class="dt">seed =</span> <span class="dv">1</span>)</span>
<span id="cb52-2"><a href="logistic-regression.html#cb52-2"></a><span class="kw">sapply</span>(vfolds, sdf_nrow)</span></code></pre></div>
<pre><code>##   fold1   fold2   fold3   fold4   fold5   fold6   fold7   fold8   fold9  fold10 
## 1001569 1003031 1005253 1002322 1001871 1000550 1002636 1002102 1001933 1002095</code></pre>
<p>This function creates a list of 10 Spark tables (“folds”), each containing (approximately) 10% of the original table, as specified by the named list <em>weights</em>.
We can now select the first fold as test set and the remaining 9 for training (in practice we would do this ten times selecting a different fold for testing each time, but not here for simplicity). To bind folds 2 to 9 we can use the convenience function <strong>sdf_bind_rows</strong>(), although <strong>do.call</strong>(rbind, …) would work as well:</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="logistic-regression.html#cb54-1"></a>training &lt;-<span class="st"> </span><span class="kw">sdf_bind_rows</span>(vfolds[<span class="dv">2</span><span class="op">:</span><span class="dv">10</span>])</span>
<span id="cb54-2"><a href="logistic-regression.html#cb54-2"></a>test &lt;-<span class="st"> </span>vfolds[[<span class="dv">1</span>]]</span></code></pre></div>
<p>Now we run the logit on the training set using the function <strong>ml_logistic_regression</strong>() and evaluate the performances on the test set using <strong>ml_evaluate</strong>():</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="logistic-regression.html#cb55-1"></a>logit &lt;-<span class="st"> </span><span class="kw">ml_logistic_regression</span>(training, <span class="dt">formula =</span> f)</span>
<span id="cb55-2"><a href="logistic-regression.html#cb55-2"></a>validation &lt;-<span class="st"> </span><span class="kw">ml_evaluate</span>(logit, test)</span>
<span id="cb55-3"><a href="logistic-regression.html#cb55-3"></a>validation</span></code></pre></div>
<pre><code>## BinaryLogisticRegressionSummaryImpl 
##  Access the following via `$` or `ml_summary()`. 
##  - features_col() 
##  - label_col() 
##  - predictions() 
##  - probability_col() 
##  - area_under_roc() 
##  - f_measure_by_threshold() 
##  - pr() 
##  - precision_by_threshold() 
##  - recall_by_threshold() 
##  - roc() 
##  - prediction_col() 
##  - accuracy() 
##  - f_measure_by_label() 
##  - false_positive_rate_by_label() 
##  - labels() 
##  - precision_by_label() 
##  - recall_by_label() 
##  - true_positive_rate_by_label() 
##  - weighted_f_measure() 
##  - weighted_false_positive_rate() 
##  - weighted_precision() 
##  - weighted_recall() 
##  - weighted_true_positive_rate()</code></pre>
<p>As shown above the object <em>validation</em> contains a number of accuracy measures. For example we can extract the ROC curve and and the area under the ROC curve (AUC) and plot them:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="logistic-regression.html#cb57-1"></a>roc &lt;-<span class="st"> </span>validation<span class="op">$</span><span class="kw">roc</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">collect</span>()</span>
<span id="cb57-2"><a href="logistic-regression.html#cb57-2"></a><span class="kw">ggplot</span>(roc, <span class="kw">aes</span>(<span class="dt">x =</span> FPR, <span class="dt">y =</span> TPR)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_abline</span>(<span class="dt">lty =</span> <span class="st">"dashed"</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="kw">paste</span>(<span class="st">"AUC:"</span>, <span class="kw">round</span>(validation<span class="op">$</span><span class="kw">area_under_roc</span>(),<span class="dv">2</span>)))</span></code></pre></div>
<p><img src="SparklyR-book_files/figure-html/roc-1.png" width="672"></p>
<p>The predictions on the test set are stored in <em>validation</em> under the field <em>predictions</em>() that has the structure:</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="logistic-regression.html#cb58-1"></a>validation<span class="op">$</span><span class="kw">predictions</span>()</span></code></pre></div>
<pre><code>## # Source: spark&lt;?&gt; [?? x 23]
##    geo      gender   age       id bmi        smoking        income  education  marital_status heart diabetes hypertension stroke cancer gvt_cost   cost state   agecat     features   label rawPrediction probability prediction
##    &lt;chr&gt;    &lt;chr&gt;  &lt;int&gt;    &lt;int&gt; &lt;chr&gt;      &lt;chr&gt;          &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;          &lt;int&gt;    &lt;int&gt;        &lt;int&gt;  &lt;int&gt;  &lt;int&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;list&gt;     &lt;dbl&gt; &lt;list&gt;        &lt;list&gt;           &lt;dbl&gt;
##  1 Aabdilli F         20 10616144 Normal     Current smoker 70K+    University separated          0        0            0      0      0    315.   351.  Itsware 18.0, 35.0 &lt;dbl [31]&gt;     0 &lt;dbl [2]&gt;     &lt;dbl [2]&gt;            0
##  2 Aabdilli F         31 12484925 Normal     Never smoked   70K+    Diploma    partnered          0        0            0      0      0     36.3   36.3 Itsware 18.0, 35.0 &lt;dbl [31]&gt;     0 &lt;dbl [2]&gt;     &lt;dbl [2]&gt;            0
##  3 Aabdilli F         37 13354911 Normal     Never smoked   70K+    University partnered          0        0            0      0      1    319.   319.  Itsware 35.0, 45.0 &lt;dbl [31]&gt;     0 &lt;dbl [2]&gt;     &lt;dbl [2]&gt;            0
##  4 Aabdilli F         44 14160212 Overweight Ex-smoker      50K-70K University partnered          0        0            0      0      0    193.   231.  Itsware 35.0, 45.0 &lt;dbl [31]&gt;     0 &lt;dbl [2]&gt;     &lt;dbl [2]&gt;            0
##  5 Aabdilli F         47 15009235 Obese      Never smoked   40K-50K University separated          0        0            0      0      1   1183.  1183.  Itsware 45.0, 55.0 &lt;dbl [31]&gt;     0 &lt;dbl [2]&gt;     &lt;dbl [2]&gt;            0
##  6 Aabdilli F         51 15792336 Overweight Never smoked   50K-70K University partnered          0        0            0      0      1    964.  1607.  Itsware 45.0, 55.0 &lt;dbl [31]&gt;     0 &lt;dbl [2]&gt;     &lt;dbl [2]&gt;            0
##  7 Aabdilli F         51 15792365 Normal     Ex-smoker      70K+    University partnered          0        0            0      0      1    579.   579.  Itsware 45.0, 55.0 &lt;dbl [31]&gt;     0 &lt;dbl [2]&gt;     &lt;dbl [2]&gt;            0
##  8 Aabdilli F         53 15792317 Obese      Never smoked   70K+    University partnered          0        0            1      0      1   2657.  3293.  Itsware 45.0, 55.0 &lt;dbl [31]&gt;     0 &lt;dbl [2]&gt;     &lt;dbl [2]&gt;            0
##  9 Aabdilli F         57 16571288 Obese      Ex-smoker      &lt;20K    Certif     partnered          0        1            1      0      0   1905.  2270.  Itsware 55.0, 65.0 &lt;dbl [31]&gt;     0 &lt;dbl [2]&gt;     &lt;dbl [2]&gt;            0
## 10 Aabdilli F         59 16571220 Obese      Never smoked   30K-40K NoCertif   partnered          0        0            1      0      0    730.   730.  Itsware 55.0, 65.0 &lt;dbl [31]&gt;     0 &lt;dbl [2]&gt;     &lt;dbl [2]&gt;            0
## # ... with more rows</code></pre>
<p>Notice that some of the columns, like “probability” are actually lists. In the case of probability the list contains the probability of labels 0 and 1 respectively.
In order to extract them and make them proper columns Spark provides the convenience function <strong>sdf_separate_column</strong>(), that takes the name of the columns we are interested in and create columns with given names:</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="logistic-regression.html#cb60-1"></a><span class="kw">sdf_separate_column</span>(validation<span class="op">$</span><span class="kw">predictions</span>(), <span class="st">"probability"</span>, <span class="dt">into=</span><span class="kw">c</span>(<span class="st">"prob0"</span>,<span class="st">"prob1"</span>))</span></code></pre></div>
<pre><code>## # Source: spark&lt;?&gt; [?? x 25]
##    geo      gender   age       id bmi        smoking        income  education  marital_status heart diabetes hypertension stroke cancer gvt_cost   cost state   agecat     features   label rawPrediction probability prediction prob0    prob1
##    &lt;chr&gt;    &lt;chr&gt;  &lt;int&gt;    &lt;int&gt; &lt;chr&gt;      &lt;chr&gt;          &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;          &lt;int&gt;    &lt;int&gt;        &lt;int&gt;  &lt;int&gt;  &lt;int&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;list&gt;     &lt;dbl&gt; &lt;list&gt;        &lt;list&gt;           &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;
##  1 Aabdilli F         20 10616144 Normal     Current smoker 70K+    University separated          0        0            0      0      0    315.   351.  Itsware 18.0, 35.0 &lt;dbl [31]&gt;     0 &lt;dbl [2]&gt;     &lt;dbl [2]&gt;            0 0.999 0.000932
##  2 Aabdilli F         31 12484925 Normal     Never smoked   70K+    Diploma    partnered          0        0            0      0      0     36.3   36.3 Itsware 18.0, 35.0 &lt;dbl [31]&gt;     0 &lt;dbl [2]&gt;     &lt;dbl [2]&gt;            0 0.999 0.000921
##  3 Aabdilli F         37 13354911 Normal     Never smoked   70K+    University partnered          0        0            0      0      1    319.   319.  Itsware 35.0, 45.0 &lt;dbl [31]&gt;     0 &lt;dbl [2]&gt;     &lt;dbl [2]&gt;            0 0.995 0.00523 
##  4 Aabdilli F         44 14160212 Overweight Ex-smoker      50K-70K University partnered          0        0            0      0      0    193.   231.  Itsware 35.0, 45.0 &lt;dbl [31]&gt;     0 &lt;dbl [2]&gt;     &lt;dbl [2]&gt;            0 0.992 0.00846 
##  5 Aabdilli F         47 15009235 Obese      Never smoked   40K-50K University separated          0        0            0      0      1   1183.  1183.  Itsware 45.0, 55.0 &lt;dbl [31]&gt;     0 &lt;dbl [2]&gt;     &lt;dbl [2]&gt;            0 0.973 0.0266  
##  6 Aabdilli F         51 15792336 Overweight Never smoked   50K-70K University partnered          0        0            0      0      1    964.  1607.  Itsware 45.0, 55.0 &lt;dbl [31]&gt;     0 &lt;dbl [2]&gt;     &lt;dbl [2]&gt;            0 0.980 0.0202  
##  7 Aabdilli F         51 15792365 Normal     Ex-smoker      70K+    University partnered          0        0            0      0      1    579.   579.  Itsware 45.0, 55.0 &lt;dbl [31]&gt;     0 &lt;dbl [2]&gt;     &lt;dbl [2]&gt;            0 0.979 0.0211  
##  8 Aabdilli F         53 15792317 Obese      Never smoked   70K+    University partnered          0        0            1      0      1   2657.  3293.  Itsware 45.0, 55.0 &lt;dbl [31]&gt;     0 &lt;dbl [2]&gt;     &lt;dbl [2]&gt;            0 0.977 0.0229  
##  9 Aabdilli F         57 16571288 Obese      Ex-smoker      &lt;20K    Certif     partnered          0        1            1      0      0   1905.  2270.  Itsware 55.0, 65.0 &lt;dbl [31]&gt;     0 &lt;dbl [2]&gt;     &lt;dbl [2]&gt;            0 0.898 0.102   
## 10 Aabdilli F         59 16571220 Obese      Never smoked   30K-40K NoCertif   partnered          0        0            1      0      0    730.   730.  Itsware 55.0, 65.0 &lt;dbl [31]&gt;     0 &lt;dbl [2]&gt;     &lt;dbl [2]&gt;            0 0.932 0.0683  
## # ... with more rows</code></pre>
<p><span style="color:#007dd1; font-size:2em;">Issue:</span> Running things on my laptop it seems that the function <strong>ml_logistic_regression</strong>() is very slow compared to<br><strong>ml_generalized_linear_regression</strong>(). The advantage of the first seems to be that its related object already contains the ROC curve, although a major disadvantage is that it does not return standard errors and p values. Also, the predicted object of the second function contains a clearly labeled column “prediction” that is the probability of class 1, so that it does not require a call to <strong>sdf_separate_column</strong>(). Overall, given how easy is it is to compute an ROC curve, it seems that <strong>ml_generalized_linear_regression</strong>() is a more interesting option.</p>

</div>
</div></body></html>

<p style="text-align: center;">
<a href="user-defined-functions-and-hive-sql.html"><button class="btn btn-default">Previous</button></a>
<a href="appendix-a-data-description.html"><button class="btn btn-default">Next</button></a>
</p>
<p class="build-date">Page built: 
2020-01-21
</p>
</div>
</div>



</body>
</html>
